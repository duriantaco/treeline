================================================================================
CHUNK 5 OF 5
================================================================================

========================================
File: ./enhanced_analyzer.py
========================================
import ast
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Optional


from treeline.models.enhanced_analyzer import QualityIssue
from treeline.aggregator.metrics import MetricsAggregator

class EnhancedCodeAnalyzer:
    def __init__(self, show_params: bool = True, config: Dict = None):
        self.show_params = show_params
        self.quality_issues = defaultdict(list)
        self.metrics_summary = defaultdict(dict)
        self.config = config or {}
        
        self.metrics_aggregator = MetricsAggregator(self.config)

    def analyze_file(self, file_path: Path) -> List[Dict]:
        """Analyze a file for code quality issues and structure"""
        try:
            content = self._read_file(file_path)
            if not content:
                return []
                
            tree = self._parse_content(content)
            if not tree:
                return []

            results = self._analyze_code_elements(tree, content, file_path)
            
            for result in results:
                if 'code_smells' not in result:
                    result['code_smells'] = []
            
            self._add_file_issues_to_elements(results, file_path)
            
            return results
        except Exception as e:
            return []

    def _add_file_issues_to_elements(self, elements: List[Dict], file_path: Path):
        """Add file-specific issues to the corresponding code elements"""
        file_path_str = str(file_path)
        
        file_issues = []
        for category, issues in self.quality_issues.items():
            for issue in issues:
                if isinstance(issue, dict) and issue.get('file_path') == file_path_str:
                    issue_with_category = issue.copy()
                    issue_with_category['category'] = category
                    file_issues.append(issue_with_category)
        
        if not file_issues:
            return
            
        elements_by_line = {}
        for element in elements:
            if 'line' in element:
                elements_by_line[element['line']] = element
        
        for issue in file_issues:
            issue_line = issue.get('line')
            if not issue_line:
                continue
                
            closest_element = None
            closest_distance = float('inf')
            
            for element_line, element in elements_by_line.items():
                if element_line <= issue_line:
                    distance = issue_line - element_line
                    if distance < closest_distance:
                        closest_distance = distance
                        closest_element = element
            
            if closest_element and closest_distance <= 100:
                issue_text = f"[{issue['category']}] {issue.get('description', 'Unknown issue')}"
                if issue_line:
                    issue_text += f" (Line {issue_line})"
                    
                closest_element['code_smells'].append(issue_text)

    def analyze_directory(self, directory: Path) -> List[Dict]:
        results = []
        for file_path in directory.rglob("*.py"):
            results.extend(self.analyze_file(file_path))
        return results

    def generate_report(self) -> str:
        report = ["# Code Quality Analysis Report"]
        for category, issues in self.quality_issues.items():
            report.append(f"## {category.title()}")
            for issue in issues:
                line_info = f" (Line {issue['line']})" if issue.get('line') else ""
                report.append(f"- {issue['description']}{line_info}")
        return "\n".join(report)

    def _read_file(self, file_path: Path) -> Optional[str]:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            self._add_issue("file", f"Could not read file: {str(e)}")
            return None

    def _parse_content(self, content: str) -> Optional[ast.AST]:
        try:
            return ast.parse(content)
        except Exception as e:
            self._add_issue("parsing", f"Could not parse content: {str(e)}")
            return None

    def _add_issue(self, category: str, description: str, file_path: str = None, line: int = None):
        issue = QualityIssue(description=description, file_path=file_path, line=line)
        self.quality_issues[category].append(issue.__dict__)

    def _analyze_code_elements(self, tree: ast.AST, content: str, file_path: Path) -> List[Dict]:
        results = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                func_info = self._analyze_function(node, content)
                self._add_quality_issues_to_element(func_info, node.lineno, file_path) 
                results.append(func_info)
                
            elif isinstance(node, ast.ClassDef):
                class_info = self._analyze_class(node, content)
                self._add_quality_issues_to_element(class_info, node.lineno, file_path)
                results.append(class_info)
    
        return results

    def _add_quality_issues_to_element(self, element_info: Dict, line_number: int, file_path: Path):
        if 'code_smells' not in element_info:
            element_info['code_smells'] = []
            
        file_path_str = str(file_path)
        
        for category, issues in self.quality_issues.items():
            for issue in issues:
                if (isinstance(issue, dict) and 
                    issue.get('file_path') == file_path_str and 
                    issue.get('line') is not None and
                    abs(issue.get('line') - line_number) <= 10):
                    
                    issue_text = f"[{category}] {issue.get('description')}"
                    if issue.get('line'):
                        issue_text += f" (Line {issue.get('line')})"
                    element_info['code_smells'].append(issue_text)

    def _analyze_function(self, node: ast.FunctionDef, content: str) -> Dict:
        func_lines = content.splitlines()[node.lineno-1:node.end_lineno]
        line_count = len(func_lines)
        docstring = ast.get_docstring(node)
        param_count = len(node.args.args)
        complexity = self._calculate_complexity(node)
        nested_depth = self._calculate_nested_depth(node)
        returns = self._count_returns(node)
        max_line_length = max(len(line.rstrip()) for line in func_lines) if func_lines else 0
        doc_length = len(docstring) if docstring else 0
        
        return {
            "type": "function",
            "name": node.name,
            "line": node.lineno,
            "docstring": docstring,
            "metrics": {
                "lines": line_count,
                "params": param_count,
                "complexity": complexity,
                "nested_depth": nested_depth,
                "returns": returns,
                "max_line_length": max_line_length,
                "doc_length": doc_length,
            },
            "code_smells": []  
        }

    def _analyze_class(self, node: ast.ClassDef, content: str) -> Dict:
        class_lines = content.splitlines()[node.lineno-1:node.end_lineno]
        line_count = len(class_lines)
        docstring = ast.get_docstring(node)
        methods = [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
        methods_count = len(methods)
        
        return {
            "type": "class",
            "name": node.name,
            "line": node.lineno,
            "docstring": docstring,
            "metrics": {
                "lines": line_count,
                "methods_count": methods_count
            },
            "code_smells": []  
        }
        
    def _calculate_complexity(self, node: ast.AST) -> int:
        """Calculate cyclomatic complexity."""
        complexity = 1
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.ExceptHandler)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        return complexity
    
    def _calculate_nested_depth(self, node: ast.AST) -> int:
        def walk_depth(current_node, current_depth):
            max_depth = current_depth
            for child in ast.iter_child_nodes(current_node):
                if isinstance(child, (ast.If, ast.For, ast.While, ast.Try, ast.With)):
                    child_depth = walk_depth(child, current_depth + 1)
                    max_depth = max(max_depth, child_depth)
                else:
                    child_depth = walk_depth(child, current_depth)
                    max_depth = max(max_depth, child_depth)
            return max_depth
        return walk_depth(node, 0)
    
    def _count_returns(self, node: ast.AST) -> int:
        return sum(1 for child in ast.walk(node) if isinstance(child, ast.Return))
========================================
File: ./renderer/renderer.js
========================================
class AdaptiveRenderer {
    constructor(container, options = {}) {
        this.container = container;
        this.options = {
            webglThreshold: 10000,
            chunkSize: 1000,
            ...options
        };

        this.renderer = null;
        this.mode = null;
    }

    async initialize(graphData) {
        const nodeCount = graphData.nodes.length;
        const hasWebGL = this._checkWebGLSupport();

        if (hasWebGL && nodeCount > this.options.webglThreshold) {
            console.log('Using WebGL renderer for large graph');
            this.renderer = new WebGLRenderer(this.container, this.options);
            this.mode = 'webgl';
        } else {
            console.log('Using D3 renderer');
            this.renderer = new OptimizedD3Renderer(this.container, this.options);
            this.mode = 'd3';
        }

        await this.renderer.initialize(graphData);
        return this.mode;
    }

    _checkWebGLSupport() {
        const canvas = document.createElement('canvas');
        const gl = canvas.getContext('webgl2') || canvas.getContext('webgl');
        return !!gl;
    }
}

class WebGLRenderer {
    constructor(container, options) {
        this.container = container;
        this.options = options;
        this.gl = null;
        this.program = null;
        this.data = null;

        this.lastFrameTime = 0;
        this.frameCount = 0;
    }

    async initialize(graphData) {
        const canvas = document.createElement('canvas');
        canvas.width = this.container.clientWidth;
        canvas.height = this.container.clientHeight;
        this.container.appendChild(canvas);

        this.gl = canvas.getContext('webgl2');
        if (!this.gl) throw new Error('WebGL2 not supported');

        await this._initShaders();
        this._initBuffers(graphData);
        this._startRenderLoop();
    }

    _initShaders() {
        const vertexShader = this.gl.createShader(this.gl.VERTEX_SHADER);
        this.gl.shaderSource(vertexShader, `#version 300 es
            in vec2 position;
            in vec3 color;
            in float size;

            uniform mat4 viewMatrix;
            uniform vec2 viewport;

            out vec3 fragColor;

            void main() {
                gl_Position = vec4(position / viewport * 2.0 - 1.0, 0.0, 1.0);
                gl_PointSize = size;
                fragColor = color;
            }
        `);
        this.gl.compileShader(vertexShader);

        const fragmentShader = this.gl.createShader(this.gl.FRAGMENT_SHADER);
        this.gl.shaderSource(fragmentShader, `#version 300 es
            precision highp float;
            in vec3 fragColor;
            out vec4 outColor;

            void main() {
                vec2 coord = gl_PointCoord - vec2(0.5);
                float r = length(coord) * 2.0;
                float alpha = 1.0 - smoothstep(0.8, 1.0, r);
                outColor = vec4(fragColor, alpha);
            }
        `);
        this.gl.compileShader(fragmentShader);

        this.program = this.gl.createProgram();
        this.gl.attachShader(this.program, vertexShader);
        this.gl.attachShader(this.program, fragmentShader);
        this.gl.linkProgram(this.program);
    }

    _initBuffers(graphData) {
        const positions = new Float32Array(graphData.nodes.length * 2);
        const colors = new Float32Array(graphData.nodes.length * 3);
        const sizes = new Float32Array(graphData.nodes.length);

        graphData.nodes.forEach((node, i) => {
            positions[i * 2] = node.x || 0;
            positions[i * 2 + 1] = node.y || 0;

            const color = this._getNodeColor(node.type);
            colors[i * 3] = color[0];
            colors[i * 3 + 1] = color[1];
            colors[i * 3 + 2] = color[2];

            sizes[i] = node.size || 5.0;
        });

        this._createBuffer('position', positions);
        this._createBuffer('color', colors);
        this._createBuffer('size', sizes);
    }

    _createBuffer(name, data) {
        const buffer = this.gl.createBuffer();
        this.gl.bindBuffer(this.gl.ARRAY_BUFFER, buffer);
        this.gl.bufferData(this.gl.ARRAY_BUFFER, data, this.gl.STATIC_DRAW);

        const location = this.gl.getAttribLocation(this.program, name);
        this.gl.enableVertexAttribArray(location);
        this.gl.vertexAttribPointer(
            location,
            name === 'position' ? 2 : name === 'color' ? 3 : 1,
            this.gl.FLOAT,
            false,
            0,
            0
        );
    }

    _startRenderLoop() {
        const render = (timestamp) => {
            this.frameCount++;
            if (timestamp - this.lastFrameTime >= 1000) {
                const fps = this.frameCount;
                this.frameCount = 0;
                this.lastFrameTime = timestamp;
                console.log(`WebGL Renderer FPS: ${fps}`);
            }

            this.gl.clear(this.gl.COLOR_BUFFER_BIT);
            this.gl.drawArrays(this.gl.POINTS, 0, this.data.nodes.length);
            requestAnimationFrame(render);
        };

        requestAnimationFrame(render);
    }

    _getNodeColor(type) {
        const colors = {
            module: [0.2, 0.4, 0.8],
            class: [0.8, 0.2, 0.4],
            function: [0.2, 0.8, 0.4],
            default: [0.5, 0.5, 0.5]
        };
        return colors[type] || colors.default;
    }
}

class OptimizedD3Renderer {
    constructor(container, options) {
        this.container = container;
        this.options = options;
        this.simulation = null;
        this.quadtree = null;
        this.visibleNodes = new Set();
    }

    async initialize(graphData) {
        const svg = d3.select(this.container)
            .append('svg')
            .attr('width', '100%')
            .attr('height', '100%');

        // chunking the nodes to avoid blocking the main thread
        const processChunk = (start) => {
            const end = Math.min(start + this.options.chunkSize, graphData.nodes.length);
            const chunk = graphData.nodes.slice(start, end);

            this.simulation.nodes(chunk);

            if (end < graphData.nodes.length) {
                setTimeout(() => processChunk(end), 0);
            }
        };

        this.simulation = d3.forceSimulation()
            .force('link', d3.forceLink().id(d => d.id))
            .force('charge', d3.forceManyBody().strength(-30))
            .force('center', d3.forceCenter(
                this.container.clientWidth / 2,
                this.container.clientHeight / 2
            ));

        processChunk(0);

        this._setupViewportCulling(svg, graphData);
    }

    _setupViewportCulling(svg, graphData) {
        this.quadtree = d3.quadtree()
            .x(d => d.x)
            .y(d => d.y)
            .addAll(graphData.nodes);

        svg.call(d3.zoom().on('zoom', () => {
            this._updateVisibleNodes();
        }));

        this._updateVisibleNodes();
    }

    _updateVisibleNodes() {
        const visible = new Set();
        const bounds = this.container.getBoundingClientRect();

        this.quadtree.visit((node, x1, y1, x2, y2) => {
            if (!node.length) {
                do {
                    const d = node.data;
                    if (d.x >= bounds.left && d.x <= bounds.right &&
                        d.y >= bounds.top && d.y <= bounds.bottom) {
                        visible.add(d.id);
                    }
                } while (node = node.next);
            }
            return x1 > bounds.right || x2 < bounds.left ||
                   y1 > bounds.bottom || y2 < bounds.top;
        });

        this.visibleNodes = visible;
        this._renderVisibleNodes();
    }

    _renderVisibleNodes() {
        d3.selectAll('.node')
            .style('display', d => this.visibleNodes.has(d.id) ? null : 'none');
    }
}

export { AdaptiveRenderer };

========================================
File: ./optimization/graph.py
========================================
from collections import defaultdict
from typing import Dict, List, Set


class OptimizedDependencyGraph:
    """High-performance graph structure for code dependencies"""

    def __init__(self):
        self.nodes: Dict[str, int] = {}  # name -> index mapping
        self.reverse_nodes: Dict[int, str] = {}  # index -> name mapping
        self.node_types: Dict[int, str] = {}  # node metadata
        self._next_index: int = 0
        self.outgoing_edges: Dict[int, Set[int]] = defaultdict(set)
        self._cache = {}

    def _get_node_index(self, name: str, node_type: str = None) -> int:
        if name not in self.nodes:
            self.nodes[name] = self._next_index
            self.reverse_nodes[self._next_index] = name
            if node_type:
                self.node_types[self._next_index] = node_type
            self._next_index += 1
        return self.nodes[name]

    def add_edge(
        self, from_node: str, to_node: str, from_type: str = None, to_type: str = None
    ):
        """Add a directed edge between nodes"""
        from_idx = self._get_node_index(from_node, from_type)
        to_idx = self._get_node_index(to_node, to_type)

        self.outgoing_edges[from_idx].add(to_idx)

        self._cache.clear()

    def get_connected_components(self) -> List[Set[str]]:
        """Get strongly connected components using efficient algorithms"""
        cache_key = "connected_components"
        if cache_key not in self._cache:
            components = self._strongly_connected_components()

            self._cache[cache_key] = components

        return self._cache[cache_key]

    def get_dependency_chain(
        self, start_node: str, max_depth: int = -1
    ) -> Dict[str, int]:
        """Get all dependencies and their distances from start node"""
        if start_node not in self.nodes:
            return {}

    def _strongly_connected_components(self) -> List[Set[str]]:
        index_counter = 0
        stack = []
        on_stack = set()
        index_map = {}
        lowlink = {}
        sccs = []

        def strongconnect(v):
            nonlocal index_counter
            index_map[v] = index_counter
            lowlink[v] = index_counter
            index_counter += 1
            stack.append(v)
            on_stack.add(v)

            for w in self.outgoing_edges[v]:
                if w not in index_map:
                    strongconnect(w)
                    lowlink[v] = min(lowlink[v], lowlink[w])
                elif w in on_stack:
                    lowlink[v] = min(lowlink[v], index_map[w])

            if lowlink[v] == index_map[v]:
                comp = set()
                while True:
                    w = stack.pop()
                    on_stack.remove(w)
                    comp.add(self.reverse_nodes[w])
                    if w == v:
                        break
                sccs.append(comp)

        for node_idx in range(self._next_index):
            if node_idx not in index_map:
                strongconnect(node_idx)

        return sccs

    def get_cycles(self) -> List[List[str]]:
        """Detect dependency cycles efficiently"""
        cache_key = "cycles"
        if cache_key in self._cache:
            return self._cache[cache_key]

        cycles = []
        visited = set()
        path = []
        path_set = set()

        def dfs(node_idx):
            if node_idx in path_set:
                cycle_start = path.index(node_idx)
                cycle = path[cycle_start:]
                cycles.append([self.reverse_nodes[i] for i in cycle])
                return

            if node_idx in visited:
                return

            visited.add(node_idx)
            path.append(node_idx)
            path_set.add(node_idx)

            row = self.adjacency_matrix[node_idx].tocoo()
            for _, col, _ in zip(row.row, row.col, row.data):
                dfs(col)

            path.pop()
            path_set.remove(node_idx)

        for node_idx in range(self._next_index):
            if node_idx not in visited:
                dfs(node_idx)

        self._cache[cache_key] = cycles
        return cycles

========================================
File: ./checkers/complexity.py
========================================
import ast
from collections import defaultdict
from pathlib import Path
from typing import Dict, List

from treeline.models.enhanced_analyzer import QualityIssue

class ComplexityAnalyzer:
    def __init__(self, config: Dict = None):
        self.config = config or {}
        self.max_cyclomatic = self.config.get("MAX_CYCLOMATIC_COMPLEXITY", 10)
        self.max_cognitive = self.config.get("MAX_COGNITIVE_COMPLEXITY", 15)

    def check(self, tree: ast.AST, file_path: Path, quality_issues: defaultdict):
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                cc = self._calculate_cyclomatic_complexity(node)
                cog = self._calculate_cognitive_complexity(node)
                element_type = "function" if isinstance(node, ast.FunctionDef) else "class"
                if cc > self.max_cyclomatic:
                    quality_issues["complexity"].append(QualityIssue(
                        description=f"High cyclomatic complexity ({cc} > {self.max_cyclomatic}) in {element_type} '{node.name}'",
                        file_path=str(file_path),
                        line=node.lineno
                    ).__dict__)
                if cog > self.max_cognitive:
                    quality_issues["complexity"].append(QualityIssue(
                        description=f"High cognitive complexity ({cog} > {self.max_cognitive}) in {element_type} '{node.name}'",
                        file_path=str(file_path),
                        line=node.lineno
                    ).__dict__)

    def _calculate_cyclomatic_complexity(self, node: ast.AST) -> int:
        complexity = 1
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.ExceptHandler)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        return complexity

    def _calculate_cognitive_complexity(self, node: ast.AST) -> int:
        def walk_cognitive(node: ast.AST, nesting: int = 0) -> int:
            complexity = 0
            for child in ast.iter_child_nodes(node):
                if isinstance(child, (ast.If, ast.While, ast.For)):
                    complexity += 1 + nesting
                    complexity += walk_cognitive(child, nesting + 1)
                elif isinstance(child, ast.BoolOp):
                    complexity += len(child.values) - 1
                else:
                    complexity += walk_cognitive(child, nesting)
            return complexity
        return walk_cognitive(node)
========================================
File: ./checkers/magic_numbers.py
========================================
from collections import defaultdict
from pathlib import Path
import ast
from typing import Dict

class MagicNumberChecker:
    def __init__(self, config: Dict = None):
        self.config = config or {}

    def check(self, tree: ast.AST, file_path: Path, quality_issues: defaultdict):
        for node in ast.walk(tree):
            if isinstance(node, ast.Constant) and isinstance(node.value, (int, float)):
                if node.value in [0, 1, -1]:
                    continue
                parent = self._get_parent(node, tree)
                if isinstance(parent, ast.Assign) and len(parent.targets) == 1 and isinstance(parent.targets[0], ast.Name):
                    continue
                quality_issues["code_smells"].append({
                    "description": "Magic number detected",
                    "file_path": str(file_path),
                    "line": node.lineno
                })

    def _get_parent(self, node, tree):
        """Find the parent node in the AST."""
        for parent in ast.walk(tree):
            for child in ast.iter_child_nodes(parent):
                if child == node:
                    return parent
        return None
========================================
File: ./checkers/style_checker.py
========================================
from collections import defaultdict
from pathlib import Path
from typing import Dict
from treeline.models.enhanced_analyzer import QualityIssue

class StyleChecker:
    def __init__(self, config: Dict = None):
        self.config = config or {}
        self.max_line_length = self.config.get("MAX_LINE_LENGTH", 80)
        self.max_file_lines = self.config.get("MAX_FILE_LINES", 500)

    def check(self, file_path: Path, quality_issues: defaultdict):
        with open(file_path, "r", encoding="utf-8") as f:
            lines = f.readlines()
        if len(lines) > self.max_file_lines:
            quality_issues["style"].append(QualityIssue(
                description=f"File has {len(lines)} lines (over {self.max_file_lines})",
                file_path=str(file_path),
                line=None
            ).__dict__)
        for i, line in enumerate(lines, start=1):
            if len(line.rstrip()) > self.max_line_length:
                quality_issues["style"].append(QualityIssue(
                    description="Line is too long",
                    file_path=str(file_path),
                    line=i
                ).__dict__)
========================================
File: ./checkers/sql_injection.py
========================================
from collections import defaultdict
from pathlib import Path
import ast
from typing import Dict

class SQLInjectionChecker:
    def __init__(self, config: Dict = None):
        self.config = config or {}

    def check(self, tree: ast.AST, file_path: Path, quality_issues: defaultdict):
        for node in ast.walk(tree):
            if (isinstance(node, ast.Call) and 
                isinstance(node.func, ast.Attribute) and 
                node.func.attr == "execute"):
                if any(isinstance(arg, ast.Constant) and isinstance(arg.value, str) for arg in node.args):
                    quality_issues["security"].append({
                        "description": "Potential SQL injection risk",
                        "file_path": str(file_path),
                        "line": node.lineno
                    })
